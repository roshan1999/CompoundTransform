{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import sys\n",
    "import nltk\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segregating the sentence into Subject predicate and object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_it_all_spacy(sen):\n",
    "#     print(sen)\n",
    "    doc = nlp(sen)\n",
    "    count=0\n",
    "    cclst = list()\n",
    "    sublst = list()\n",
    "    verblst = list()\n",
    "    subjlst = list()\n",
    "    objlst = list()\n",
    "    for token in doc:\n",
    "        count+=1\n",
    "        ## Checks for the speech tag of word having a coordinating conjunction or \"For\" or \"So\"\n",
    "        if \"CC\" in token.pos_ or \" for \" == \" \"+str(token)+\" \" or  \" so \" == \" \"+str(token)+\" \":\n",
    "            cclst.append([count,str(token)])\n",
    "    if len(cclst)==0:\n",
    "        ## Append the coordinating conjunction along with its relative position\n",
    "        cclst.append([count,\"CCab\"])\n",
    "    count = 0\n",
    "    for token in doc:\n",
    "        count+=1\n",
    "        if \"VERB\" in token.pos_ or \"AUX\" in token.pos_:\n",
    "            ## Checks for speech tag of word having verb\n",
    "            verblst.append([count,str(token)])\n",
    "    if len(verblst)==0:\n",
    "        ## Append the verb along with its relative position\n",
    "        verblst.append([count,\"VBab\"])\n",
    "    count = 0\n",
    "    for token in doc:\n",
    "        count+=1\n",
    "        if \"NOUN\" in token.pos_ or \"PRON\" in token.pos_ or \"PROPN\" in token.pos_:\n",
    "            sublst.append([count,str(token)])\n",
    "    if len(sublst)==0:\n",
    "        ## Append the noun along with its relative position\n",
    "        sublst.append([count,\"SBab\"])\n",
    "#     print(\"Subject = \",sublst)\n",
    "#     print(\"Verb = \",verblst)\n",
    "    k=0\n",
    "    r=0\n",
    "    i=0;\n",
    "    flag = 0\n",
    "    ccoccur = cclst[i][0]\n",
    "    verboccur = verblst[k][0]   \n",
    "    try:\n",
    "        ## Use the verb of the relative position with relative noun.\n",
    "        ## If the verb occurs before the noun then append as object else append as subject.\n",
    "        ## but this is not necessarily the case everytime.. \n",
    "        ## I like playing basketball and I like playing football. \n",
    "        ## In ^ above case -- \"I\" that occurs before the verb \"like\" is taken as subject. \n",
    "        ## but for the same case \"basketball\" since it occurs after \"like\" becomes object.\n",
    "        ## this is the simple case.. in the same example.. if the verb is still \"like\" of the \n",
    "        ## first clause, then \"I\" of the second clause is made object, hence it is necessary to locate\n",
    "        ## the correct verb with respect to which the noun is taken. \n",
    "        ## the following code deals with locating the verb\n",
    "        while verboccur< sublst[r][0]: # Checks for auxillary verbal conditions\n",
    "            k+=1\n",
    "            verboccur = verblst[k][0]\n",
    "    except: # If no auxillary verb\n",
    "        k-=1\n",
    "        verboccur = verblst[k][0]\n",
    "    try:    \n",
    "        flag = 0\n",
    "        while (1):\n",
    "            j = sublst[r]\n",
    "#             print(\"Accessing , \",j[1],verblst[k][1])\n",
    "            ccoccur = cclst[i][0]\n",
    "            verboccur = verblst[k][0]\n",
    "            if j[0]<=verboccur: # Checks whether subject occurs before or after the verb.. and accordingly appends.\n",
    "                subjlst.append([j[0],j[1]])\n",
    "            if j[0]>verboccur:\n",
    "                objlst.append([j[0],j[1]])\n",
    "            r+=1 # Iterating to next noun, \n",
    "            try:\n",
    "                j = sublst[r] # If next noun exists\n",
    "            except:\n",
    "                j = sublst[r-1] # If next noun doesnt exist\n",
    "            if j[0]>=verboccur: # Locate the next verb if the next noun exists\n",
    "                try:\n",
    "                    while(j[0]>verboccur):\n",
    "                        k+=1\n",
    "                        verboccur = verblst[k][0]\n",
    "                except: # reflect back to previous verb if the next verb was not successfully located\n",
    "                    k-=1\n",
    "                    verboccur = verblst[k][0]\n",
    "#                 print(k,verblst[k])\n",
    "            if(flag==1): # Terminating condition check\n",
    "                try:\n",
    "                    objlst.append([sublst[r][0],sublst[r][1]]) # If noun exists then last noun is object\n",
    "                except:\n",
    "#                     print(\"no last object\")\n",
    "                    pass\n",
    "#                 print(\"broke\")\n",
    "                break;\n",
    "\n",
    "            if(sublst[r][0]>=ccoccur): # Creating terminating condition... \n",
    "                try:\n",
    "                    i+=1    \n",
    "                    ccoccur = cclst[i][0] # If no forward coordinating conjunction, then no more breaks required.\n",
    "                except:\n",
    "                    i-=1\n",
    "                    flag = 1; # Hence check one last time for clause and then break\n",
    "#             print(ccoccur)\n",
    "\n",
    "    except:\n",
    "#         print(sys.exc_info()[0])\n",
    "        pass\n",
    "#     print(subjlst,objlst)\n",
    "#     print(verblst)\n",
    "#     print(cclst)\n",
    "    return (subjlst,objlst,verblst,cclst)\n",
    "#Data preparation completed\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rule 1 segregation\n",
    "##### -- Breaking conjunction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rule 1 segregation\n",
    "# Breaking conjunction\n",
    "def rule_1(sen):\n",
    "    subjlst,objlst,verblst,cclst = get_it_all_spacy(sen)\n",
    "    doc = nlp(sen)\n",
    "#     print(subjlst,objlst,verblst,cclst)\n",
    "    broke = list()\n",
    "    i =0\n",
    "    j=0\n",
    "    count = len(cclst)\n",
    "    if cclst[0][1] == \"CCab\" : # If no coordinating conjunction--already simple sentence\n",
    "        return([],[],[\"\",sen],1) # 1 == sends check to main to say \"not a compound sentence\"\n",
    "    else:\n",
    "        try:\n",
    "            cap = cclst[i][1] # Locate the next coordinating conjunction and break the sentence further\n",
    "            while (1):\n",
    "#                 print(str(doc[j]))\n",
    "    #             print(cap)\n",
    "                cap = cclst[i][1]\n",
    "                if str(cap).strip()==str(doc[j]):\n",
    "    #                 print(str(doc[j]))\n",
    "                    broke.append(j) # Append the location of the clauses to the broke list.\n",
    "                    count-=1\n",
    "                    if count!=0: # Check for multiple conjunctions\n",
    "                        i+=1\n",
    "                    else:\n",
    "                        break\n",
    "                j+=1\n",
    "        except:\n",
    "#             print(sys.exc_info()[0])\n",
    "            pass\n",
    "        # The following code appends the clause to the fin list depending on the broke locations.\n",
    "        broke.append(len(str(doc))) \n",
    "#         print(broke)\n",
    "        fin = list()\n",
    "        fin.append(str(doc[0:broke[0]]))\n",
    "        try:\n",
    "            for i in range(len(broke)):\n",
    "                fin.append(str(doc[broke[i]+1:broke[i+1]]))\n",
    "        except:\n",
    "#             print(sys.exec_info()[0])\n",
    "            pass\n",
    "    final= list()\n",
    "    for i in fin:\n",
    "    #     print(i)\n",
    "        stri = str()    \n",
    "        for j in i:\n",
    "            stri+= j\n",
    "        final.append(stri) # converting each word of the token to a string and appending the string\n",
    "    broke = final\n",
    "#     print(broke)\n",
    "    for i in broke:\n",
    "        if i == \"\": # if broke has any non existent string then remove.\n",
    "            broke.remove(i)\n",
    "    return (subjlst,objlst,broke,0) # Returns check as 0 to say \"Compound sentence\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rule 2 or Rule 3 check\n",
    "#### -- accordingly decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule_2_3(empsubjlst,allavail,onlyobjlst,onlysubjlst):\n",
    "    count = 0\n",
    "    try:\n",
    "        # The following works on rule 2 or 3 check plus performs \n",
    "        # the rules on the lists provided it passes rule 1\n",
    "        while len(empsubjlst)!=0: # If no subject then perform reverse rule 2\n",
    "            # The following performs rule3\n",
    "            extract = len(allavail)-1 # Gets the most recently used string to append to the subject. \n",
    "            subj3lst,obj3lst,verb3lst,cc3lst = get_it_all_spacy(allavail[extract][1])\n",
    "            for i in empsubjlst:\n",
    "                finstr= subj3lst[0][1]+\" \"+i[1] # appends the string to the subject\n",
    "                count=subj3lst[0][0]+1\n",
    "                allavail.append([count,finstr]) # appends the string to the list of simple sentences\n",
    "#                 print(finstr)\n",
    "                empsubjlst.remove(i) # removes the string from the incomplete sentence list\n",
    "        while len(onlyobjlst)!=0: \n",
    "            # For normal rule2 usecase\n",
    "            # extract finds the most recently used string\n",
    "            # appends to that string the object\n",
    "            # removes the incomplete clause and adds the complete simple sentence to the \n",
    "            # list of simple sentences.\n",
    "            extract = len(allavail)-1\n",
    "#             print(extract,len(allavail))\n",
    "            subj3lst,obj3lst,verb3lst,cc3lst = get_it_all_spacy(allavail[extract][1])\n",
    "            objlen=len(obj3lst)-1\n",
    "            prestr = allavail[extract][1].replace(obj3lst[objlen][1],\"\")\n",
    "        #     print(prestr)\n",
    "            for i in onlyobjlst:\n",
    "                finstr = prestr+\" \"+i[1]\n",
    "                count=allavail[extract][0]+1\n",
    "                allavail.append([count,finstr])\n",
    "#                 print(finstr)\n",
    "                onlyobjlst.remove(i)\n",
    "        while len(onlysubjlst)!=0:\n",
    "            # When only subject exists:\n",
    "            # This is the reverse rule2 case:\n",
    "            # gets the next complete sentence between which the subject exists.\n",
    "            # appends this subject to the predicate and object of the corresponding found sentence\n",
    "            # appends the final simple complete sentence to list of complete sentences\n",
    "            # removes the incomplete sentence/ subject from the onlysubjlist.\n",
    "            for i in onlysubjlst:\n",
    "                extract = i[0]+1\n",
    "                for j in range(len(allavail)):\n",
    "                    if allavail[j][0] == extract:\n",
    "                        extract = j\n",
    "                        break\n",
    "#                 print(extract)\n",
    "                subj3lst,obj3lst,verb3lst,cc3lst = get_it_all_spacy(allavail[extract][1])\n",
    "                subjlen = len(subj3lst)-1\n",
    "                prestr = allavail[extract][1].replace(subj3lst[subjlen][1],\"\")\n",
    "                finstr = i[1]+\" \"+prestr\n",
    "                count=allavail[extract][0]+1\n",
    "                allavail.append([count,finstr])\n",
    "#                 print(finstr)\n",
    "                onlysubjlst.remove(i)\n",
    "        return (allavail)\n",
    "    except:\n",
    "#         print(sys.exc_info())\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main function.. performs rule 1 and checks whether rule1 is sufficient else performs rule2 or 3 check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rule 1 check\n",
    "def main(sen,fw):\n",
    "    subjlst,objlst,broke,check = rule_1(sen)\n",
    "#     print(\"\\n------\\n\")\n",
    "    ## Check denotes whether the sentence is already simple or not.\n",
    "    if(check):\n",
    "#         fw.write(sen+\"\\n\")\n",
    "        for i in broke:\n",
    "            fw.write(i)\n",
    "        return\n",
    "    ## The following lists are used to segregate rule 1 complete/incomplete..\n",
    "    ## if incomplete then prepares data for rule2 and 3\n",
    "    allavail = list()\n",
    "    empsubjlst = list()\n",
    "    empobjlst = list()\n",
    "    empverblst = list()\n",
    "    onlyobjlst = list()\n",
    "    onlysubjlst = list()\n",
    "    count=0;\n",
    "    total = len(broke)\n",
    "    for i in broke:\n",
    "        ## Checks all sentences of the conjunction broke sentences. \n",
    "        subj=1;\n",
    "        verb=1;\n",
    "        obj=1;\n",
    "        count+=1\n",
    "        ## The following line gets the broken sentence's predicate subject and object.\n",
    "        subj2lst,obj2lst,verb2lst,cc2lst = get_it_all_spacy(i.strip())\n",
    "        print(\"New stripped sentence = \",subj2lst,obj2lst,verb2lst,cc2lst)\n",
    "        print(\"Origial sentence connotation= \",subjlst,objlst)\n",
    "        ## if no subject: turn variable of subj 0 to denote.. no subject.\n",
    "        if len(subj2lst)==0:\n",
    "            subj=0\n",
    "            if len(obj2lst)!=0:\n",
    "                ## it is possible that object of the sentence may not be an object in the \n",
    "                ## original sentence before breaking by conjunction instead could be a subject\n",
    "                ## in such case it finds the whether subject or object of original sentence\n",
    "                ## and makes subj variable 1 and obj variable 0\n",
    "                if any(obj2lst[0][1] in ls for ls in subjlst):\n",
    "                    print(\"Check\",obj2lst[0][1],subjlst)\n",
    "                    subj=1\n",
    "                    obj=0\n",
    "        if len(obj2lst)==0:\n",
    "            obj=0;\n",
    "            ## Similarly performs similar checking for subject of the sentence and makes \n",
    "            ## necessary variables show it. \n",
    "            if len(subj2lst)!=0:\n",
    "                if any(subj2lst[0][1] in ls for ls in objlst):\n",
    "                    print(\"Check\",subj2lst[0][1],objlst)\n",
    "                    subj=0\n",
    "                    obj=1\n",
    "        ## If there is no verb in the sentence.. in case of dependent clauses. \n",
    "        if verb2lst[0][1]==\"VBab\":\n",
    "            verb=0;\n",
    "        if subj==0 and verb!=0 and obj!=0:\n",
    "            ## empsubjlst is for the dependant clauses.. - rule 3\n",
    "            empsubjlst.append([count,i])\n",
    "        if subj==0 and verb==0 and obj!=0:\n",
    "            ## onlyobjlst is for the independant clauses -- rule2\n",
    "            onlyobjlst.append([count,i])\n",
    "        if subj!=0 and verb!=0:\n",
    "            ## allavail -- clauses that are simple and independent\n",
    "            lstnew = list()\n",
    "            it = i\n",
    "            try:\n",
    "                if verb2lst[0][0]==1:\n",
    "                    lstnew = i.split()\n",
    "                    temp = lstnew[0]\n",
    "                    lstnew[0]=lstnew[1]\n",
    "                    lstnew[1] = temp\n",
    "                    i=\"\"\n",
    "                    for word in lstnew:\n",
    "                        i+=word+ \" \"\n",
    "                print(i)\n",
    "            except:\n",
    "                i = it;\n",
    "            allavail.append([count,i])\n",
    "        if subj!=0 and verb==0 and obj==0:\n",
    "            ## For reverse rule 2 case where only subject exists in the dependant clause.\n",
    "            onlysubjlst.append([count,i])\n",
    "        print(empsubjlst,onlysubjlst,onlyobjlst,allavail)\n",
    "    # Check for case in Rule2 or Rule3:\n",
    "    if len(broke)==len(allavail):\n",
    "#         fw.write(sen+\"\\n\")\n",
    "        for i in allavail:\n",
    "            print(re.sub(' +', ' ',i[1]).strip())\n",
    "            fw.write(re.sub(' +', ' ',i[1]).strip()+\"\\n\") \n",
    "    else:\n",
    "        try:\n",
    "            allavail = rule_2_3(empsubjlst,allavail,onlyobjlst,onlysubjlst)\n",
    "#             fw.write(sen+\"\\n\")\n",
    "            for i in allavail:\n",
    "                print(re.sub(r'\\b(.+)\\s+\\1\\b', r'\\1', re.sub(' +', ' ',i[1]).strip()))\n",
    "                fw.write(re.sub(r'\\b(.+)\\s+\\1\\b', r'\\1', re.sub(' +', ' ',i[1]).strip()))\n",
    "        except:\n",
    "            fw.write(sen)\n",
    "            print(sys.exc_info()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sepereate the sentences that have bare semi colon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep_semi(input):\n",
    "    rw = open(input)\n",
    "    fw = open(\"tempoutput.txt\",\"w\")\n",
    "    for line in rw:\n",
    "        line = re.sub(\"[^\\P{P}\\.;]|\",\"\",str(nlp(line)))\n",
    "        fw.write(line+\"\\n\")\n",
    "#         r = line.split(\". \")\n",
    "#         for i in r:\n",
    "#             if i==\" \":\n",
    "#                 r.remove(i)\n",
    "# #         fw.write(line+\"\\n\")\n",
    "#         if(len(r)!=0):\n",
    "#             for i in r:\n",
    "#                 fw.write(i+\"\\n\")\n",
    "    rw.close()\n",
    "    fw.close()\n",
    "    rw = open(\"tempoutput.txt\")\n",
    "    lst = list()\n",
    "    for line in rw:\n",
    "        lst.append(line.split(\";\"))\n",
    "    rw.close()\n",
    "    rw = open(\"tempoutput.txt\",\"w\")\n",
    "    for i in lst:\n",
    "        if(len(i)>1):\n",
    "            for sep in i:\n",
    "                rw.write(sep.strip())\n",
    "                rw.write(\"\\n\")\n",
    "        else:\n",
    "            rw.write(i[0])\n",
    "#                 print(sep.strip())\n",
    "    fw.close()\n",
    "    rw.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function that coordinates with the main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the location of the input file: test_combined.txt\n",
      "New stripped sentence =  [[3, 'dog']] [[7, 'prizes']] [[4, 'has'], [5, 'won']] [[7, 'CCab']]\n",
      "Origial sentence connotation=  [[3, 'dog'], [7, 'prizes'], [9, 'he']] [[10, 'doesnâ€']]\n",
      "The black dog has won many prizes\n",
      "[] [] [] [[1, 'The black dog has won many prizes']]\n",
      "New stripped sentence =  [[1, 'he'], [2, 'doesnâ€'], [3, '™'], [4, 't']] [[7, 'tricks']] [[5, 'know']] [[8, 'CCab']]\n",
      "Origial sentence connotation=  [[3, 'dog'], [7, 'prizes'], [9, 'he']] [[10, 'doesnâ€']]\n",
      "he doesnâ€™t know many tricks.\n",
      "\n",
      "[] [] [] [[1, 'The black dog has won many prizes'], [2, 'he doesnâ€™t know many tricks.\\n']]\n",
      "The black dog has won many prizes\n",
      "he doesnâ€™t know many tricks.\n",
      "New stripped sentence =  [[1, 'She'], [4, 'cat']] [[7, 'front'], [9, 'her']] [[2, 'saw'], [5, 'run']] [[9, 'CCab']]\n",
      "Origial sentence connotation=  [[1, 'She'], [4, 'cat'], [7, 'front'], [9, 'her'], [11, 'she']] []\n",
      "She saw a cat run in front of her\n",
      "[] [] [] [[1, 'She saw a cat run in front of her']]\n",
      "New stripped sentence =  [[1, 'she']] [] [[2, 'fell'], [5, 'rollerskating']] [[6, 'CCab']]\n",
      "Origial sentence connotation=  [[1, 'She'], [4, 'cat'], [7, 'front'], [9, 'her'], [11, 'she']] []\n",
      "she fell down while rollerskating.\n",
      "\n",
      "[] [] [] [[1, 'She saw a cat run in front of her'], [2, 'she fell down while rollerskating.\\n']]\n",
      "She saw a cat run in front of her\n",
      "she fell down while rollerskating.\n",
      "New stripped sentence =  [] [[7, 'meteor'], [9, 'shower'], [13, 'space']] [[3, 'was']] [[13, 'CCab']]\n",
      "Origial sentence connotation=  [[7, 'meteor'], [9, 'shower'], [13, 'space'], [19, 'crew']] [[34, 'meteors']]\n",
      "Check meteor [[7, 'meteor'], [9, 'shower'], [13, 'space'], [19, 'crew']]\n",
      "There  was  a  meteor  shower  in  space  \n",
      "[] [] [] [[1, 'There  was  a  meteor  shower  in  space  ']]\n",
      "New stripped sentence =  [[3, 'crew']] [[18, 'meteors']] [[5, 'did'], [9, 'know'], [15, 'avoid']] [[19, 'CCab']]\n",
      "Origial sentence connotation=  [[7, 'meteor'], [9, 'shower'], [13, 'space'], [19, 'crew']] [[34, 'meteors']]\n",
      " the  crew  did  not  know  how  to  avoid  the meteors.\n",
      "\n",
      "[] [] [] [[1, 'There  was  a  meteor  shower  in  space  '], [2, ' the  crew  did  not  know  how  to  avoid  the meteors.\\n']]\n",
      "There was a meteor shower in space\n",
      "the crew did not know how to avoid the meteors.\n",
      "New stripped sentence =  [[1, 'I']] [[6, 'baby'], [7, 'Chihuahua']] [[2, 'wanted'], [4, 'buy']] [[7, 'CCab']]\n",
      "Origial sentence connotation=  [[1, 'I'], [6, 'baby'], [7, 'Chihuahua'], [9, 'I']] [[14, 'money']]\n",
      "I wanted to buy a baby Chihuahua\n",
      "[] [] [] [[1, 'I wanted to buy a baby Chihuahua']]\n",
      "New stripped sentence =  [[1, 'I']] [[6, 'money']] [[2, 'started'], [4, 'save']] [[7, 'CCab']]\n",
      "Origial sentence connotation=  [[1, 'I'], [6, 'baby'], [7, 'Chihuahua'], [9, 'I']] [[14, 'money']]\n",
      "I started to save my money.\n",
      "\n",
      "[] [] [] [[1, 'I wanted to buy a baby Chihuahua'], [2, 'I started to save my money.\\n']]\n",
      "I wanted to buy a baby Chihuahua\n",
      "I started to save my money.\n",
      "New stripped sentence =  [[1, 'Gillian']] [] [[2, 'did'], [4, 'like'], [6, 'read']] [[6, 'CCab']]\n",
      "Origial sentence connotation=  [[1, 'Gillian'], [8, 'she']] [[14, 'it']]\n",
      "Gillian did not like to read\n",
      "[] [] [] [[1, 'Gillian did not like to read']]\n",
      "New stripped sentence =  [[1, 'she']] [[7, 'it']] [[2, 'was']] [[8, 'CCab']]\n",
      "Origial sentence connotation=  [[1, 'Gillian'], [8, 'she']] [[14, 'it']]\n",
      "she was not very good at it.\n",
      "\n",
      "[] [] [] [[1, 'Gillian did not like to read'], [2, 'she was not very good at it.\\n']]\n",
      "Gillian did not like to read\n",
      "she was not very good at it.\n",
      "New stripped sentence =  [[1, 'Pam']] [[5, 'Wayne']] [[3, 'liked']] [[5, 'CCab']]\n",
      "Origial sentence connotation=  [[1, 'Pam'], [5, 'Wayne'], [8, 'Leena']] [[11, 'Wayne']]\n",
      "Pam  liked  Wayne  \n",
      "[] [] [] [[1, 'Pam  liked  Wayne  ']]\n",
      "New stripped sentence =  [[1, 'Leena']] [[4, 'Wayne']] [[3, 'liked']] [[5, 'CCab']]\n",
      "Origial sentence connotation=  [[1, 'Pam'], [5, 'Wayne'], [8, 'Leena']] [[11, 'Wayne']]\n",
      "Leena also liked Wayne.\n",
      "\n",
      "[] [] [] [[1, 'Pam  liked  Wayne  '], [2, 'Leena also liked Wayne.\\n']]\n",
      "Pam liked Wayne\n",
      "Leena also liked Wayne.\n",
      "New stripped sentence =  [[1, 'You']] [[6, 'baby']] [[2, 'could'], [3, 'cry']] [[6, 'CCab']]\n",
      "Origial sentence connotation=  [[1, 'You'], [6, 'baby'], [8, 'you']] [[12, 'room']]\n",
      "You could cry like a baby\n",
      "[] [] [] [[1, 'You could cry like a baby']]\n",
      "New stripped sentence =  [[1, 'you']] [[5, 'room'], [8, 'adult']] [[2, 'can'], [3, 'clean']] [[9, 'CCab']]\n",
      "Origial sentence connotation=  [[1, 'You'], [6, 'baby'], [8, 'you']] [[12, 'room']]\n",
      "you can clean your room like an adult.\n",
      "\n",
      "[] [] [] [[1, 'You could cry like a baby'], [2, 'you can clean your room like an adult.\\n']]\n",
      "You could cry like a baby\n",
      "you can clean your room like an adult.\n",
      "New stripped sentence =  [[1, 'She'], [2, 'didnâ€'], [3, '™'], [4, 't']] [[9, 'Jill']] [[5, 'want'], [7, 'play']] [[9, 'CCab']]\n",
      "Origial sentence connotation=  [[1, 'She'], [2, 'didnâ€'], [3, '™'], [4, 't'], [9, 'Jill'], [11, 'she']] [[12, 'didnâ€']]\n",
      "She didnâ€™t want to play with Jill\n",
      "[] [] [] [[1, 'She didnâ€™t want to play with Jill']]\n",
      "New stripped sentence =  [[1, 'she'], [2, 'didnâ€'], [3, '™'], [4, 't']] [[9, 'Tim']] [[5, 'want'], [7, 'play']] [[10, 'CCab']]\n",
      "Origial sentence connotation=  [[1, 'She'], [2, 'didnâ€'], [3, '™'], [4, 't'], [9, 'Jill'], [11, 'she']] [[12, 'didnâ€']]\n",
      "she didnâ€™t want to play with Tim.\n",
      "\n",
      "[] [] [] [[1, 'She didnâ€™t want to play with Jill'], [2, 'she didnâ€™t want to play with Tim.\\n']]\n",
      "She didnâ€™t want to play with Jill\n",
      "she didnâ€™t want to play with Tim.\n",
      "New stripped sentence =  [[1, 'Arleenâ€'], [2, '™'], [3, 's']] [[9, 'boy']] [[4, 'could'], [6, 'play']] [[9, 'CCab']]\n",
      "Origial sentence connotation=  [[1, 'Arleenâ€'], [2, '™'], [3, 's'], [9, 'boy'], [12, 'she']] [[17, 'boy']]\n",
      "Arleenâ€™s could not play with that boy\n",
      "[] [] [] [[1, 'Arleenâ€™s could not play with that boy']]\n",
      "New stripped sentence =  [[2, 'she']] [[7, 'boy']] [[1, 'could'], [3, 'play']] [[8, 'CCab']]\n",
      "Origial sentence connotation=  [[1, 'Arleenâ€'], [2, '™'], [3, 's'], [9, 'boy'], [12, 'she']] [[17, 'boy']]\n",
      "she could play with that other boy. \n",
      "[] [] [] [[1, 'Arleenâ€™s could not play with that boy'], [2, 'she could play with that other boy. ']]\n",
      "Arleenâ€™s could not play with that boy\n",
      "she could play with that other boy.\n",
      "New stripped sentence =  [[1, 'Letâ€'], [2, '™']] [[7, 'swimming'], [8, 'pool']] [[3, 's'], [4, 'go']] [[8, 'CCab']]\n",
      "Origial sentence connotation=  [[1, 'Letâ€'], [2, '™'], [7, 'swimming'], [8, 'pool'], [10, 'itâ€']] [[11, '™']]\n",
      "Letâ€™s go to the swimming pool\n",
      "[] [] [] [[1, 'Letâ€™s go to the swimming pool']]\n",
      "New stripped sentence =  [[1, 'itâ€'], [2, '™']] [[7, 'house']] [[3, 's']] [[8, 'CCab']]\n",
      "Origial sentence connotation=  [[1, 'Letâ€'], [2, '™'], [7, 'swimming'], [8, 'pool'], [10, 'itâ€']] [[11, '™']]\n",
      "itâ€™s hot inside the house.\n",
      "\n",
      "[] [] [] [[1, 'Letâ€™s go to the swimming pool'], [2, 'itâ€™s hot inside the house.\\n']]\n",
      "Letâ€™s go to the swimming pool\n",
      "itâ€™s hot inside the house.\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# Splits sentences by the semi colon\n",
    "# also removes punctuations\n",
    "sep_semi(input(\"Enter the location of the input file: \"))\n",
    "rw = open(\"tempoutput.txt\")\n",
    "fw = open(\"output.txt\",\"w\")\n",
    "for i in rw:\n",
    "    main(i,fw)   \n",
    "rw.close()\n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen  = \"I have never visited africa nor have I visited Asia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjlst,objlst,broke,check = rule_1(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[1, 'I'], [5, 'africa'], [8, 'I']],\n",
       " [[10, 'Asia']],\n",
       " [[2, 'have'], [4, 'visited'], [7, 'have'], [9, 'visited']],\n",
       " [[6, 'nor']])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_it_all_spacy(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New stripped sentence =  [[1, 'I']] [[5, 'africa']] [[2, 'have'], [4, 'visited']] [[5, 'CCab']]\n",
      "Origial sentence connotation=  [[1, 'I'], [5, 'africa'], [8, 'I']] [[10, 'Asia']]\n",
      "I have never visited africa\n",
      "[] [] [] [[1, 'I have never visited africa']]\n",
      "New stripped sentence =  [[2, 'I']] [[4, 'Asia']] [[1, 'have'], [3, 'visited']] [[4, 'CCab']]\n",
      "Origial sentence connotation=  [[1, 'I'], [5, 'africa'], [8, 'I']] [[10, 'Asia']]\n",
      "I have visited Asia \n",
      "[] [] [] [[1, 'I have never visited africa'], [2, 'I have visited Asia ']]\n",
      "I have never visited africa\n",
      "I have visited Asia\n"
     ]
    }
   ],
   "source": [
    "allavail = list()\n",
    "empsubjlst = list()\n",
    "empobjlst = list()\n",
    "empverblst = list()\n",
    "onlyobjlst = list()\n",
    "onlysubjlst = list()\n",
    "count=0;\n",
    "total = len(broke)\n",
    "for i in broke:\n",
    "    ## Checks all sentences of the conjunction broke sentences. \n",
    "    subj=1;\n",
    "    verb=1;\n",
    "    obj=1;\n",
    "    count+=1\n",
    "    ## The following line gets the broken sentence's predicate subject and object.\n",
    "    subj2lst,obj2lst,verb2lst,cc2lst = get_it_all_spacy(i.strip())\n",
    "    print(\"New stripped sentence = \",subj2lst,obj2lst,verb2lst,cc2lst)\n",
    "    print(\"Origial sentence connotation= \",subjlst,objlst)\n",
    "    ## if no subject: turn variable of subj 0 to denote.. no subject.\n",
    "    if len(subj2lst)==0:\n",
    "        subj=0\n",
    "        if len(obj2lst)!=0:\n",
    "            ## it is possible that object of the sentence may not be an object in the \n",
    "            ## original sentence before breaking by conjunction instead could be a subject\n",
    "            ## in such case it finds the whether subject or object of original sentence\n",
    "            ## and makes subj variable 1 and obj variable 0\n",
    "            if any(obj2lst[0][1] in ls for ls in subjlst):\n",
    "                print(\"Check\",obj2lst[0][1],subjlst)\n",
    "                subj=1\n",
    "                obj=0\n",
    "    if len(obj2lst)==0:\n",
    "        obj=0;\n",
    "        ## Similarly performs similar checking for subject of the sentence and makes \n",
    "        ## necessary variables show it. \n",
    "        if len(subj2lst)!=0:\n",
    "            if any(subj2lst[0][1] in ls for ls in objlst):\n",
    "                print(\"Check\",subj2lst[0][1],objlst)\n",
    "                subj=0\n",
    "                obj=1\n",
    "    ## If there is no verb in the sentence.. in case of dependent clauses. \n",
    "    if verb2lst[0][1]==\"VBab\":\n",
    "        verb=0;\n",
    "    if subj==0 and verb!=0 and obj!=0:\n",
    "        ## empsubjlst is for the dependant clauses.. - rule 3\n",
    "        empsubjlst.append([count,i])\n",
    "    if subj==0 and verb==0 and obj!=0:\n",
    "        ## onlyobjlst is for the independant clauses -- rule2\n",
    "        onlyobjlst.append([count,i])\n",
    "    if subj!=0 and verb!=0:\n",
    "        ## allavail -- clauses that are simple and independent\n",
    "        lstnew = list()\n",
    "        if verb2lst[0][0]==1:\n",
    "            lstnew = i.split()\n",
    "            temp = lstnew[0]\n",
    "            lstnew[0]=lstnew[1]\n",
    "            lstnew[1] = temp\n",
    "            i=\"\"\n",
    "            for word in lstnew:\n",
    "                i+=word+ \" \"\n",
    "        print(i)\n",
    "        allavail.append([count,i])\n",
    "    if subj!=0 and verb==0 and obj==0:\n",
    "        ## For reverse rule 2 case where only subject exists in the dependant clause.\n",
    "        onlysubjlst.append([count,i])\n",
    "    print(empsubjlst,onlysubjlst,onlyobjlst,allavail)\n",
    "# Check for case in Rule2 or Rule3:\n",
    "if len(broke)==len(allavail):\n",
    "#         fw.write(\"Sentence = \"+sen+\"\\n\")\n",
    "    for i in allavail:\n",
    "        print(re.sub(' +', ' ',i[1]).strip())\n",
    "#             fw.write(\"\\t\"+re.sub(' +', ' ',i[1]).strip()+\"\\n\") \n",
    "#         fw.write(\"\\n-----\\n\")\n",
    "else:\n",
    "    try:\n",
    "        allavail = rule_2_3(empsubjlst,allavail,onlyobjlst,onlysubjlst)\n",
    "#             fw.write(\"Sentence = \"+sen+\"\\n\")\n",
    "        for i in allavail:\n",
    "            print(re.sub(r'\\b(.+)\\s+\\1\\b', r'\\1', re.sub(' +', ' ',i[1]).strip()))\n",
    "#                 fw.write(\"\\t\"+re.sub(r'\\b(.+)\\s+\\1\\b', r'\\1', re.sub(' +', ' ',i[1]).strip())+\"\\n\")\n",
    "#             fw.write(\"\\n-----\\n\")\n",
    "    except:\n",
    "#             fw.write(\"Sentence = \"+sen+\"\\n\")\n",
    "        print(sys.exc_info()[0])\n",
    "#             fw.write(\"\\tAlready Simple\\n\")\n",
    "#             fw.write(\"\\n-----\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
