{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "!python3 -m pip install --user stanfordnlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence resolution --- enter your string in 4th cell as stri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanfordnlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/home/roshan/stanfordnlp_resources/en_ewt_models/en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/home/roshan/stanfordnlp_resources/en_ewt_models/en_ewt_tagger.pt', 'pretrain_path': '/home/roshan/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/home/roshan/stanfordnlp_resources/en_ewt_models/en_ewt_lemmatizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': '/home/roshan/stanfordnlp_resources/en_ewt_models/en_ewt_parser.pt', 'pretrain_path': '/home/roshan/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "#Load the settings of each parameter.\n",
    "pip = stanfordnlp.Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/home/roshan/stanfordnlp_resources/en_ewt_models/en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/home/roshan/stanfordnlp_resources/en_ewt_models/en_ewt_tagger.pt', 'pretrain_path': '/home/roshan/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/home/roshan/stanfordnlp_resources/en_ewt_models/en_ewt_lemmatizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': '/home/roshan/stanfordnlp_resources/en_ewt_models/en_ewt_parser.pt', 'pretrain_path': '/home/roshan/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n",
      "('Barack', '4', 'nsubj:pass')\n",
      "('Obama', '1', 'flat')\n",
      "('was', '4', 'aux:pass')\n",
      "('born', '0', 'root')\n",
      "('in', '6', 'case')\n",
      "('Hawaii', '4', 'obl')\n",
      "('.', '4', 'punct')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:14: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nlp = stanfordnlp.Pipeline(processors='tokenize,mwt,pos,lemma,depparse', lang='en')\n",
    "doc = pip(\"Barack Obama was born in Hawaii.  He was elected president in 2008.\")\n",
    "doc.sentences[0].print_dependencies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---> Attributes of parser: (trial and error)\n",
    "##### word.text = word that falls in the dependency\n",
    "##### word.index = index of word\n",
    "##### word.governor.text = word that governs the word that falls in the dependency\n",
    "##### word.governor = index of governor\n",
    "##### word.dependency_relation = get relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/home/roshan/stanfordnlp_resources/en_ewt_models/en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/home/roshan/stanfordnlp_resources/en_ewt_models/en_ewt_tagger.pt', 'pretrain_path': '/home/roshan/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/home/roshan/stanfordnlp_resources/en_ewt_models/en_ewt_lemmatizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': '/home/roshan/stanfordnlp_resources/en_ewt_models/en_ewt_parser.pt', 'pretrain_path': '/home/roshan/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n",
      "compound(Place - 1 , names - 3)\n",
      "punct(- - 2 , names - 3)\n",
      "nsubj:pass(names - 3 , marked - 5)\n",
      "aux:pass(are - 4 , marked - 5)\n",
      "root(marked - 5 , root - 0)\n",
      "case(in - 6 , Arabic - 7)\n",
      "obl(Arabic - 7 , marked - 5)\n",
      "punct(, - 8 , are - 11)\n",
      "cc(and - 9 , are - 11)\n",
      "expl(there - 10 , are - 11)\n",
      "conj(are - 11 , marked - 5)\n",
      "det(some - 12 , names - 16)\n",
      "advmod(well - 13 , known - 15)\n",
      "punct(- - 14 , known - 15)\n",
      "amod(known - 15 , names - 16)\n",
      "nsubj(names - 16 , are - 11)\n",
      "case(like - 17 , Kanauj - 18)\n",
      "nmod(Kanauj - 18 , names - 16)\n",
      "case(in - 19 , Pradesh - 21)\n",
      "compound(Uttar - 20 , Pradesh - 21)\n",
      "nmod(Pradesh - 21 , Kanauj - 18)\n",
      "punct(( - 22 , Qanauj - 23)\n",
      "appos(Qanauj - 23 , Pradesh - 21)\n",
      "punct() - 24 , Qanauj - 23)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:14: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    }
   ],
   "source": [
    "#----------#\n",
    "stri = \"Place-names are marked in Arabic, and there are some well-known names like Kanauj in Uttar Pradesh (Qanauj).But look at the areas inland.Equally important is the fact that the science of cartography differed in the two periods.\"\n",
    "lst = stri.split(\".\")\n",
    "lst\n",
    "#specify the sentence and process the sentence using the parser to form dependecies\n",
    "nlp = stanfordnlp.Pipeline(processors='tokenize,mwt,pos,lemma,depparse', lang='en')\n",
    "doc = nlp(lst[0])\n",
    "print(*[f\"{word.dependency_relation}({word.text} - {word.index} , {(doc.sentences[0].words[word.governor-1].text if word.governor > 0 else 'root')} - {word.governor})\" for word in doc.sentences[0].words], sep='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Word index=1;text=Place;lemma=place;upos=NOUN;xpos=NN;feats=Number=Sing;governor=3;dependency_relation=compound>\n",
      "<Word index=2;text=-;lemma=-;upos=PUNCT;xpos=HYPH;feats=_;governor=3;dependency_relation=punct>\n",
      "<Word index=3;text=names;lemma=name;upos=NOUN;xpos=NNS;feats=Number=Plur;governor=5;dependency_relation=nsubj:pass>\n",
      "<Word index=4;text=are;lemma=be;upos=AUX;xpos=VBP;feats=Mood=Ind|Tense=Pres|VerbForm=Fin;governor=5;dependency_relation=aux:pass>\n",
      "<Word index=5;text=marked;lemma=mark;upos=VERB;xpos=VBN;feats=Tense=Past|VerbForm=Part|Voice=Pass;governor=0;dependency_relation=root>\n",
      "<Word index=6;text=in;lemma=in;upos=ADP;xpos=IN;feats=_;governor=7;dependency_relation=case>\n",
      "<Word index=7;text=Arabic;lemma=Arabic;upos=PROPN;xpos=NNP;feats=Number=Sing;governor=5;dependency_relation=obl>\n",
      "<Word index=8;text=,;lemma=,;upos=PUNCT;xpos=,;feats=_;governor=11;dependency_relation=punct>\n",
      "<Word index=9;text=and;lemma=and;upos=CCONJ;xpos=CC;feats=_;governor=11;dependency_relation=cc>\n",
      "<Word index=10;text=there;lemma=there;upos=PRON;xpos=EX;feats=_;governor=11;dependency_relation=expl>\n",
      "<Word index=11;text=are;lemma=be;upos=VERB;xpos=VBP;feats=Mood=Ind|Tense=Pres|VerbForm=Fin;governor=5;dependency_relation=conj>\n",
      "<Word index=12;text=some;lemma=some;upos=DET;xpos=DT;feats=_;governor=16;dependency_relation=det>\n",
      "<Word index=13;text=well;lemma=well;upos=ADV;xpos=RB;feats=Degree=Pos;governor=15;dependency_relation=advmod>\n",
      "<Word index=14;text=-;lemma=-;upos=PUNCT;xpos=HYPH;feats=_;governor=15;dependency_relation=punct>\n",
      "<Word index=15;text=known;lemma=know;upos=VERB;xpos=VBN;feats=Tense=Past|VerbForm=Part;governor=16;dependency_relation=amod>\n",
      "<Word index=16;text=names;lemma=name;upos=NOUN;xpos=NNS;feats=Number=Plur;governor=11;dependency_relation=nsubj>\n",
      "<Word index=17;text=like;lemma=like;upos=ADP;xpos=IN;feats=_;governor=18;dependency_relation=case>\n",
      "<Word index=18;text=Kanauj;lemma=Kanauj;upos=PROPN;xpos=NNP;feats=Number=Sing;governor=16;dependency_relation=nmod>\n",
      "<Word index=19;text=in;lemma=in;upos=ADP;xpos=IN;feats=_;governor=21;dependency_relation=case>\n",
      "<Word index=20;text=Uttar;lemma=Uttar;upos=PROPN;xpos=NNP;feats=Number=Sing;governor=21;dependency_relation=compound>\n",
      "<Word index=21;text=Pradesh;lemma=pradesh;upos=PROPN;xpos=NNP;feats=Number=Sing;governor=18;dependency_relation=nmod>\n",
      "<Word index=22;text=(;lemma=(;upos=PUNCT;xpos=-LRB-;feats=_;governor=23;dependency_relation=punct>\n",
      "<Word index=23;text=Qanauj;lemma=Qanauj;upos=PROPN;xpos=NNP;feats=Number=Sing;governor=21;dependency_relation=appos>\n",
      "<Word index=24;text=);lemma=);upos=PUNCT;xpos=-RRB-;feats=_;governor=23;dependency_relation=punct>\n"
     ]
    }
   ],
   "source": [
    "#Recognizing the attributes of the list and processing governor words based on root existence.\n",
    "lst = list()\n",
    "for word in doc.sentences[0].words:\n",
    "    print(word)\n",
    "    if(word.governor>1):\n",
    "        lst.append((word.dependency_relation, word.text,word.index,doc.sentences[0].words[word.governor-1].text,word.governor))\n",
    "    else:\n",
    "        lst.append((word.dependency_relation, word.text,word.index,doc.sentences[0].words[word.governor-1].text,\"root\"))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('compound', 'Place', '1', 'names', 3),\n",
       " ('punct', '-', '2', 'names', 3),\n",
       " ('nsubj:pass', 'names', '3', 'marked', 5),\n",
       " ('aux:pass', 'are', '4', 'marked', 5),\n",
       " ('root', 'marked', '5', ')', 'root'),\n",
       " ('case', 'in', '6', 'Arabic', 7),\n",
       " ('obl', 'Arabic', '7', 'marked', 5),\n",
       " ('punct', ',', '8', 'are', 11),\n",
       " ('cc', 'and', '9', 'are', 11),\n",
       " ('expl', 'there', '10', 'are', 11),\n",
       " ('conj', 'are', '11', 'marked', 5),\n",
       " ('det', 'some', '12', 'names', 16),\n",
       " ('advmod', 'well', '13', 'known', 15),\n",
       " ('punct', '-', '14', 'known', 15),\n",
       " ('amod', 'known', '15', 'names', 16),\n",
       " ('nsubj', 'names', '16', 'are', 11),\n",
       " ('case', 'like', '17', 'Kanauj', 18),\n",
       " ('nmod', 'Kanauj', '18', 'names', 16),\n",
       " ('case', 'in', '19', 'Pradesh', 21),\n",
       " ('compound', 'Uttar', '20', 'Pradesh', 21),\n",
       " ('nmod', 'Pradesh', '21', 'Kanauj', 18),\n",
       " ('punct', '(', '22', 'Qanauj', 23),\n",
       " ('appos', 'Qanauj', '23', 'Pradesh', 21),\n",
       " ('punct', ')', '24', 'Qanauj', 23)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#final list with dependencies as in accordance to the research paper.\n",
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nsubj:pass', 'names', '3', 'marked', 5),\n",
       " ':',\n",
       " ('compound', 'Place', '1', 'names', 3),\n",
       " ('punct', '-', '2', 'names', 3),\n",
       " ('aux:pass', 'are', '4', 'marked', 5),\n",
       " ('root', 'marked', '5', ')', 'root'),\n",
       " ('obl', 'Arabic', '7', 'marked', 5),\n",
       " ('conj', 'are', '11', 'marked', 5),\n",
       " ('det', 'some', '12', 'names', 16),\n",
       " ('amod', 'known', '15', 'names', 16),\n",
       " ('nmod', 'Kanauj', '18', 'names', 16),\n",
       " '\\n',\n",
       " ('nsubj', 'names', '16', 'are', 11),\n",
       " ':',\n",
       " ('compound', 'Place', '1', 'names', 3),\n",
       " ('punct', '-', '2', 'names', 3),\n",
       " ('aux:pass', 'are', '4', 'marked', 5),\n",
       " ('punct', ',', '8', 'are', 11),\n",
       " ('cc', 'and', '9', 'are', 11),\n",
       " ('expl', 'there', '10', 'are', 11),\n",
       " ('conj', 'are', '11', 'marked', 5),\n",
       " ('det', 'some', '12', 'names', 16),\n",
       " ('amod', 'known', '15', 'names', 16),\n",
       " ('nmod', 'Kanauj', '18', 'names', 16),\n",
       " '\\n']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting the sentence into compound and complex sentence\n",
    "res = list();\n",
    "fin = list();\n",
    "k =0;\n",
    "flag=0\n",
    "for i in lst:\n",
    "    # print(i[0])\n",
    "    if(\"subj\" in i[0]):\n",
    "        # print(\"true\")\n",
    "        str1 = i[1]\n",
    "        str2 = i[3]\n",
    "        res.clear()\n",
    "        res.append(i)\n",
    "        res.append((\":\"))\n",
    "        # print(res)\n",
    "        # Detecting the complex or compound by its subject dependency.\n",
    "        for j in lst:\n",
    "            #tracing the graph for mapping of the word and governor\n",
    "            if(\"subj\" not in j[0] and (str1 in j[1] or str1 in j[3] or str2 in j[1] or str2 in j[3]) ):\n",
    "                flag = 1\n",
    "                res = res[:] + [j]\n",
    "        #creating list of separate sentences. \n",
    "        if(flag==1):\n",
    "            fin = fin[:] + res\n",
    "            fin.append(\"\\n\")\n",
    "            # print(fin)\n",
    "            flag = 0\n",
    "fin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -- --- Above working perfectly.. need to test on multiple lines.. NOT VERY ACCURATE ----- ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To make it into a file #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing df for csv file\n",
    "res = list()\n",
    "df = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing the list-- > for every \"\\n\" (added in previous code) --> new sentence. \n",
    "k = 0\n",
    "for i in fin:\n",
    "    if \"\\n\" in i :\n",
    "        #k pointer incremented to count number of sentences.\n",
    "        k = k+1\n",
    "    if \":\" not in i:\n",
    "        # colon added (in above code) to seperate sentences based on their subject.\n",
    "        lst = list(i)\n",
    "        lst.insert(0,k)\n",
    "        a = tuple(lst)\n",
    "        res.append(a)\n",
    "df = df.append(res)\n",
    "df.to_csv(\"./dependecy list\") #stores in home directory with name dependency list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to avoid overflow when final list = 0  hence added case of ignorance\n",
    "l=0\n",
    "if(len(fin)==0):\n",
    "    res = [l] + [None]*5\n",
    "    df = df.append(res,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>nsubj:pass</td>\n",
       "      <td>names</td>\n",
       "      <td>3</td>\n",
       "      <td>marked</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>compound</td>\n",
       "      <td>Place</td>\n",
       "      <td>1</td>\n",
       "      <td>names</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>punct</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>names</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>aux:pass</td>\n",
       "      <td>are</td>\n",
       "      <td>4</td>\n",
       "      <td>marked</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "      <td>marked</td>\n",
       "      <td>5</td>\n",
       "      <td>)</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>obl</td>\n",
       "      <td>Arabic</td>\n",
       "      <td>7</td>\n",
       "      <td>marked</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>conj</td>\n",
       "      <td>are</td>\n",
       "      <td>11</td>\n",
       "      <td>marked</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>det</td>\n",
       "      <td>some</td>\n",
       "      <td>12</td>\n",
       "      <td>names</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>amod</td>\n",
       "      <td>known</td>\n",
       "      <td>15</td>\n",
       "      <td>names</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>nmod</td>\n",
       "      <td>Kanauj</td>\n",
       "      <td>18</td>\n",
       "      <td>names</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>\\n</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>names</td>\n",
       "      <td>16</td>\n",
       "      <td>are</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>compound</td>\n",
       "      <td>Place</td>\n",
       "      <td>1</td>\n",
       "      <td>names</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>punct</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>names</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>aux:pass</td>\n",
       "      <td>are</td>\n",
       "      <td>4</td>\n",
       "      <td>marked</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>punct</td>\n",
       "      <td>,</td>\n",
       "      <td>8</td>\n",
       "      <td>are</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>cc</td>\n",
       "      <td>and</td>\n",
       "      <td>9</td>\n",
       "      <td>are</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>expl</td>\n",
       "      <td>there</td>\n",
       "      <td>10</td>\n",
       "      <td>are</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>conj</td>\n",
       "      <td>are</td>\n",
       "      <td>11</td>\n",
       "      <td>marked</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>det</td>\n",
       "      <td>some</td>\n",
       "      <td>12</td>\n",
       "      <td>names</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>amod</td>\n",
       "      <td>known</td>\n",
       "      <td>15</td>\n",
       "      <td>names</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>nmod</td>\n",
       "      <td>Kanauj</td>\n",
       "      <td>18</td>\n",
       "      <td>names</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>\\n</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0           1       2     3       4     5\n",
       "0   0  nsubj:pass   names     3  marked     5\n",
       "1   0    compound   Place     1   names     3\n",
       "2   0       punct       -     2   names     3\n",
       "3   0    aux:pass     are     4  marked     5\n",
       "4   0        root  marked     5       )  root\n",
       "5   0         obl  Arabic     7  marked     5\n",
       "6   0        conj     are    11  marked     5\n",
       "7   0         det    some    12   names    16\n",
       "8   0        amod   known    15   names    16\n",
       "9   0        nmod  Kanauj    18   names    16\n",
       "10  1          \\n    None  None    None  None\n",
       "11  1       nsubj   names    16     are    11\n",
       "12  1    compound   Place     1   names     3\n",
       "13  1       punct       -     2   names     3\n",
       "14  1    aux:pass     are     4  marked     5\n",
       "15  1       punct       ,     8     are    11\n",
       "16  1          cc     and     9     are    11\n",
       "17  1        expl   there    10     are    11\n",
       "18  1        conj     are    11  marked     5\n",
       "19  1         det    some    12   names    16\n",
       "20  1        amod   known    15   names    16\n",
       "21  1        nmod  Kanauj    18   names    16\n",
       "22  2          \\n    None  None    None  None"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing dataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Made many modifications in python file but now that works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
