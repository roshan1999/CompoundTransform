{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stanfordnlp\n",
      "  Using cached https://files.pythonhosted.org/packages/41/bf/5d2898febb6e993fcccd90484cba3c46353658511a41430012e901824e94/stanfordnlp-0.2.0-py3-none-any.whl\n",
      "Collecting numpy (from stanfordnlp)\n",
      "  Using cached https://files.pythonhosted.org/packages/e5/e6/c3fdc53aed9fa19d6ff3abf97dfad768ae3afce1b7431f7500000816bda5/numpy-1.17.2-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting protobuf (from stanfordnlp)\n",
      "  Using cached https://files.pythonhosted.org/packages/eb/f4/a27952733796330cd17c17ea1f974459f5fefbbad119c0f296a6d807fec3/protobuf-3.9.1-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting torch>=1.0.0 (from stanfordnlp)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/57/d5cceb0799c06733eefce80c395459f28970ebb9e896846ce96ab579a3f1/torch-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (748.8MB)\n",
      "\u001b[K     |████████████████████████████████| 748.9MB 62kB/s  eta 0:00:01     |██████████████▌                 | 340.2MB 719kB/s eta 0:09:28     |██████████████████████████████  | 703.4MB 452kB/s eta 0:01:41\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/lib/python3/dist-packages (from stanfordnlp) (2.9.1)\n",
      "Collecting tqdm (from stanfordnlp)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dc/88/d3213e2f3492daf09d8b41631ad6899f56db17ce83ea9c8a579902bafe5e/tqdm-4.35.0-py2.py3-none-any.whl (50kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 828kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from protobuf->stanfordnlp) (20.7.0)\n",
      "Requirement already satisfied: six>=1.9 in /home/roshan/.local/lib/python3.6/site-packages (from protobuf->stanfordnlp) (1.9.0)\n",
      "Installing collected packages: numpy, protobuf, torch, tqdm, stanfordnlp\n",
      "Successfully installed numpy-1.17.2 protobuf-3.9.1 stanfordnlp-0.2.0 torch-1.2.0 tqdm-4.35.0\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install --user stanfordnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanfordnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/home/roshan/stanfordnlp_resources/en_ewt_models/en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/home/roshan/stanfordnlp_resources/en_ewt_models/en_ewt_tagger.pt', 'pretrain_path': '/home/roshan/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/home/roshan/stanfordnlp_resources/en_ewt_models/en_ewt_lemmatizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': '/home/roshan/stanfordnlp_resources/en_ewt_models/en_ewt_parser.pt', 'pretrain_path': '/home/roshan/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "pip = stanfordnlp.Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Barack', '4', 'nsubj:pass')\n",
      "('Obama', '1', 'flat')\n",
      "('was', '4', 'aux:pass')\n",
      "('born', '0', 'root')\n",
      "('in', '6', 'case')\n",
      "('Hawaii', '4', 'obl')\n",
      "('.', '4', 'punct')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:14: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    }
   ],
   "source": [
    "nlp = stanfordnlp.Pipeline(processors='tokenize,mwt,pos,lemma,depparse', lang='en')\n",
    "doc = pip(\"Barack Obama was born in Hawaii.  He was elected president in 2008.\")\n",
    "doc.sentences[0].print_dependencies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---> NOTE:\n",
    "##### word.text = word that falls in the dependency\n",
    "##### word.index = index of word\n",
    "##### word.governor.text = word that governs the word that falls in the dependency\n",
    "##### word.governor = index of governor\n",
    "##### word.dependency_relation = get relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/home/roshan/stanfordnlp_resources/en_ewt_models/en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/home/roshan/stanfordnlp_resources/en_ewt_models/en_ewt_tagger.pt', 'pretrain_path': '/home/roshan/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/home/roshan/stanfordnlp_resources/en_ewt_models/en_ewt_lemmatizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': '/home/roshan/stanfordnlp_resources/en_ewt_models/en_ewt_parser.pt', 'pretrain_path': '/home/roshan/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n",
      "nsubj(Sachin - 1 , played - 10)\n",
      "flat(Tendulkar - 2 , Sachin - 1)\n",
      "nsubj(who - 3 , MP - 6)\n",
      "cop(is - 4 , MP - 6)\n",
      "det(a - 5 , MP - 6)\n",
      "acl:relcl(MP - 6 , Sachin - 1)\n",
      "case(of - 7 , Parliament - 9)\n",
      "compound(Indian - 8 , Parliament - 9)\n",
      "nmod(Parliament - 9 , MP - 6)\n",
      "root(played - 10 , root - 0)\n",
      "obj(cricket - 11 , played - 10)\n",
      "punct(. - 12 , played - 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/LegacyDefinitions.cpp:14: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    }
   ],
   "source": [
    "#----------#\n",
    "nlp = stanfordnlp.Pipeline(processors='tokenize,mwt,pos,lemma,depparse', lang='en')\n",
    "doc = nlp(\"Sachin Tendulkar who is a MP of Indian Parliament played cricket.\")\n",
    "print(*[f\"{word.dependency_relation}({word.text} - {word.index} , {(doc.sentences[0].words[word.governor-1].text if word.governor > 0 else 'root')} - {word.governor})\" for word in doc.sentences[0].words], sep='\\n')\n",
    "lst = list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Word index=1;text=Sachin;lemma=Sachin;upos=PROPN;xpos=NNP;feats=Number=Sing;governor=10;dependency_relation=nsubj>\n",
      "<Word index=2;text=Tendulkar;lemma=tendulkar;upos=PROPN;xpos=NNP;feats=Number=Sing;governor=1;dependency_relation=flat>\n",
      "<Word index=3;text=who;lemma=who;upos=PRON;xpos=WP;feats=PronType=Rel;governor=6;dependency_relation=nsubj>\n",
      "<Word index=4;text=is;lemma=be;upos=AUX;xpos=VBZ;feats=Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin;governor=6;dependency_relation=cop>\n",
      "<Word index=5;text=a;lemma=a;upos=DET;xpos=DT;feats=Definite=Ind|PronType=Art;governor=6;dependency_relation=det>\n",
      "<Word index=6;text=MP;lemma=mp;upos=NOUN;xpos=NN;feats=Number=Sing;governor=1;dependency_relation=acl:relcl>\n",
      "<Word index=7;text=of;lemma=of;upos=ADP;xpos=IN;feats=_;governor=9;dependency_relation=case>\n",
      "<Word index=8;text=Indian;lemma=Indian;upos=PROPN;xpos=NNP;feats=Number=Sing;governor=9;dependency_relation=compound>\n",
      "<Word index=9;text=Parliament;lemma=parliament;upos=PROPN;xpos=NNP;feats=Number=Sing;governor=6;dependency_relation=nmod>\n",
      "<Word index=10;text=played;lemma=play;upos=VERB;xpos=VBD;feats=Mood=Ind|Tense=Past|VerbForm=Fin;governor=0;dependency_relation=root>\n",
      "<Word index=11;text=cricket;lemma=cricket;upos=NOUN;xpos=NN;feats=Number=Sing;governor=10;dependency_relation=obj>\n",
      "<Word index=12;text=.;lemma=.;upos=PUNCT;xpos=.;feats=_;governor=10;dependency_relation=punct>\n"
     ]
    }
   ],
   "source": [
    "lst = list()\n",
    "for word in doc.sentences[0].words:\n",
    "    print(word)\n",
    "    if(word.governor>1):\n",
    "        lst.append((word.dependency_relation, word.text,word.index,doc.sentences[0].words[word.governor-1].text,word.governor))\n",
    "    else:\n",
    "        lst.append((word.dependency_relation, word.text,word.index,doc.sentences[0].words[word.governor-1].text,\"root\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('acl:relcl', 'MP', '6', 'Sachin', 'root'),\n",
       " ('case', 'of', '7', 'Parliament', 9),\n",
       " ('compound', 'Indian', '8', 'Parliament', 9),\n",
       " ('cop', 'is', '4', 'MP', 6),\n",
       " ('det', 'a', '5', 'MP', 6),\n",
       " ('flat', 'Tendulkar', '2', 'Sachin', 'root'),\n",
       " ('nmod', 'Parliament', '9', 'MP', 6),\n",
       " ('nsubj', 'Sachin', '1', 'played', 10),\n",
       " ('nsubj', 'who', '3', 'MP', 6),\n",
       " ('obj', 'cricket', '11', 'played', 10),\n",
       " ('punct', '.', '12', 'played', 10),\n",
       " ('root', 'played', '10', '.', 'root')]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acl:relcl\n",
      "case\n",
      "compound\n",
      "cop\n",
      "det\n",
      "flat\n",
      "nmod\n",
      "nsubj\n",
      "true\n",
      "nsubj\n",
      "true\n",
      "obj\n",
      "punct\n",
      "root\n"
     ]
    }
   ],
   "source": [
    "res = list();\n",
    "fin = list();\n",
    "k =0;\n",
    "for i in lst:\n",
    "    print(i[0])\n",
    "    if(\"subj\" in i[0]):\n",
    "        print(\"true\")\n",
    "        str1 = i[1]\n",
    "        str2 = i[3]\n",
    "        res.append(i)\n",
    "        res.append(\":\")\n",
    "        for j in lst:\n",
    "            if(\"subj\" not in j[0] and (str1 in j[1] or str1 in j[3] or str2 in j[1] or str2 in j[3]) ):\n",
    "                flag = 1\n",
    "                res.append(j)\n",
    "    if(flag==1):\n",
    "        fin.append(res)\n",
    "        flag = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('nsubj', 'Sachin', '1', 'played', 10),\n",
       "  ':',\n",
       "  ('acl:relcl', 'MP', '6', 'Sachin', 'root'),\n",
       "  ('flat', 'Tendulkar', '2', 'Sachin', 'root'),\n",
       "  ('obj', 'cricket', '11', 'played', 10),\n",
       "  ('punct', '.', '12', 'played', 10),\n",
       "  ('root', 'played', '10', '.', 'root'),\n",
       "  ('nsubj', 'who', '3', 'MP', 6),\n",
       "  ':',\n",
       "  ('acl:relcl', 'MP', '6', 'Sachin', 'root'),\n",
       "  ('cop', 'is', '4', 'MP', 6),\n",
       "  ('det', 'a', '5', 'MP', 6),\n",
       "  ('nmod', 'Parliament', '9', 'MP', 6)],\n",
       " [('nsubj', 'Sachin', '1', 'played', 10),\n",
       "  ':',\n",
       "  ('acl:relcl', 'MP', '6', 'Sachin', 'root'),\n",
       "  ('flat', 'Tendulkar', '2', 'Sachin', 'root'),\n",
       "  ('obj', 'cricket', '11', 'played', 10),\n",
       "  ('punct', '.', '12', 'played', 10),\n",
       "  ('root', 'played', '10', '.', 'root'),\n",
       "  ('nsubj', 'who', '3', 'MP', 6),\n",
       "  ':',\n",
       "  ('acl:relcl', 'MP', '6', 'Sachin', 'root'),\n",
       "  ('cop', 'is', '4', 'MP', 6),\n",
       "  ('det', 'a', '5', 'MP', 6),\n",
       "  ('nmod', 'Parliament', '9', 'MP', 6)]]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
